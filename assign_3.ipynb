{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v7mqEmcY9cz3",
    "outputId": "5d06c170-16f9-4483-ed70-d0d02784ab57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ML_Assignment2' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/lrburle/ML_Assignment3.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_XRGWMF9cz0"
   },
   "source": [
    "# Assignment 3 - Landon Burleson \n",
    "## Problem 1\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3iukuJrm9cz4"
   },
   "outputs": [],
   "source": [
    "#Adding in the necessary modules needed to complete Assignment 3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    " \n",
    "# adding the subfolder to the path.\n",
    "# sys.path.insert(0, './ML_Assignment3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling in the MNIST test data.\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train_full, y_train_full), (x_test, y_test) = mnist.load_data() \n",
    "\n",
    "#Splits the dataset for validation and training datasets. \n",
    "x_valid, x_train = x_train_full[:5000] / 255.0, x_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 19:45:58.334897: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-22 19:45:58.335232: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n",
      "\n",
      "systemMemory: 24.00 GB\n",
      "maxCacheSize: 8.00 GB\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (Conv2D)              (None, 28, 28, 256)       2560      \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling2D)     (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 14, 14, 128)       295040    \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 14, 14, 128)       147584    \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling2D)     (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv4 (Conv2D)              (None, 7, 7, 64)          73792     \n",
      "                                                                 \n",
      " conv5 (Conv2D)              (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " maxpool3 (MaxPooling2D)     (None, 3, 3, 64)          0         \n",
      "                                                                 \n",
      " conv6 (Conv2D)              (None, 3, 3, 32)          18464     \n",
      "                                                                 \n",
      " conv7 (Conv2D)              (None, 3, 3, 32)          9248      \n",
      "                                                                 \n",
      " maxpool4 (MaxPooling2D)     (None, 1, 1, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " deep1 (Dense)               (None, 128)               4224      \n",
      "                                                                 \n",
      " deep2 (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 589,130\n",
      "Trainable params: 589,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 19:45:58.905487: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-10-22 19:45:59.181270: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - ETA: 0s - loss: 0.1708 - accuracy: 0.9452"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 19:46:40.965684: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 44s 23ms/step - loss: 0.1708 - accuracy: 0.9452 - val_loss: 0.0586 - val_accuracy: 0.9824\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 39s 23ms/step - loss: 0.0554 - accuracy: 0.9839 - val_loss: 0.0525 - val_accuracy: 0.9842\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 39s 23ms/step - loss: 0.0435 - accuracy: 0.9876 - val_loss: 0.0360 - val_accuracy: 0.9904\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 40s 23ms/step - loss: 0.0334 - accuracy: 0.9904 - val_loss: 0.0426 - val_accuracy: 0.9872\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 38s 22ms/step - loss: 0.0294 - accuracy: 0.9912 - val_loss: 0.0381 - val_accuracy: 0.9886\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 37s 22ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.0318 - val_accuracy: 0.9918\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 37s 22ms/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 0.0328 - val_accuracy: 0.9914\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 37s 21ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 0.0657 - val_accuracy: 0.9836\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 38s 22ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.0338 - val_accuracy: 0.9904\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 38s 22ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.0345 - val_accuracy: 0.9934\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 38s 22ms/step - loss: 0.0164 - accuracy: 0.9955 - val_loss: 0.0318 - val_accuracy: 0.9930\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 38s 22ms/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 0.0348 - val_accuracy: 0.9934\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 38s 22ms/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 0.0357 - val_accuracy: 0.9922\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 38s 22ms/step - loss: 0.0131 - accuracy: 0.9964 - val_loss: 0.0394 - val_accuracy: 0.9926\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 37s 22ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.0533 - val_accuracy: 0.9896\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 42s 24ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.0404 - val_accuracy: 0.9922\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 41s 24ms/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.0587 - val_accuracy: 0.9896\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 38s 22ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.0370 - val_accuracy: 0.9936\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 38s 22ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0452 - val_accuracy: 0.9904\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 38s 22ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.0570 - val_accuracy: 0.9912\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 39s 23ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.0485 - val_accuracy: 0.9912\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 39s 23ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 0.0451 - val_accuracy: 0.9920\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 37s 22ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.0457 - val_accuracy: 0.9920\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 37s 21ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.0535 - val_accuracy: 0.9912\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 37s 22ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.0885 - val_accuracy: 0.9904\n",
      " 20/313 [>.............................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 20:02:02.276687: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step\n",
      "Predicted value: 0, actual digit: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creating the sequential model\n",
    "cnn_model = keras.models.Sequential([\n",
    "    #Convolution front end.\n",
    "    keras.layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", input_shape = [28, 28, 1], name=\"conv1\"),\n",
    "    keras.layers.MaxPooling2D((2, 2), name=\"maxpool1\"),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", name=\"conv2\"),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", name=\"conv3\"),\n",
    "    keras.layers.MaxPooling2D((2, 2), name=\"maxpool2\"),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"conv4\"), \n",
    "    keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", name=\"conv5\"), \n",
    "    keras.layers.MaxPooling2D((2, 2), name=\"maxpool3\"),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", name=\"conv6\"), \n",
    "    keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", name=\"conv7\"), \n",
    "    keras.layers.MaxPooling2D((2, 2), name=\"maxpool4\"),\n",
    "\n",
    "\t#Deep learning layers\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation=\"relu\", name=\"deep1\"), #Dense layers can be atributed to a 'regular' hidden layer of neurons\n",
    "    keras.layers.Dense(10, activation=\"softmax\", name=\"deep2\") \n",
    "])\n",
    "\n",
    "#Shows the whole network topology for the compiled CNN\n",
    "cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#Compiling the model with a loss, optimizer, and other metrics\n",
    "cnn_model.summary()\n",
    "\n",
    "#Training the network.\n",
    "history = cnn_model.fit(x_train, y_train, epochs=25, validation_data=(x_valid,y_valid))\n",
    "loss1 = history.loss\n",
    "\n",
    "#Extracting the weights and biases from the neural network by layer name.\n",
    "# hidden1_weights = cnn_model.get_layer(\"deep1\").weights\n",
    "# hidden1_bias = cnn_model.get_layer(\"deep1\").bias.numpy()\n",
    "\n",
    "#Using the trained model to make predictions based on the input\n",
    "# probability_model = tf.keras.Sequential([cnn_model, \n",
    "#                                          tf.keras.layers.Softmax()])\n",
    "\n",
    "#Predicts what the image represents. \n",
    "# x_test = x_test / 255.0 #Normalizes the input images\n",
    "# predictions = probability_model.predict(x_test)\n",
    "\n",
    "# # #Returns the most probable output layer based on the input image at index 3\n",
    "# print('Predicted value: ' + str(np.argmax(predictions[3])) + ', actual digit: ' + str(y_test[3]))\n",
    "\n",
    "# array = x_test[3]\n",
    "x = np.linspace(1, 25)\n",
    "\n",
    "# #Show the current image\n",
    "plt.figure()\n",
    "plt.title(\"Architectural CNN Performance Comparison\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(x, loss1, 'or', label=\"Regular CNN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DzgCOkj9cz2"
   },
   "source": [
    "## Problem 2\n",
    "\n",
    "The following code demonstrates the LaNet7 architecture in tensorflow using the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST dataset \n",
    "mnist = keras.datasets.mnist\n",
    "(x_train_full, y_train_full), (x_test, y_test) = mnist.load_data() \n",
    "\n",
    "#Splits the dataset for validation and training datasets. \n",
    "x_valid, x_train = x_train_full[:5000] / 255.0, x_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(6, (5, 5), padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)),\n",
    "    keras.layers.Conv2D(16, (5, 5), strides=(1, 1), padding='same', activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)),\n",
    "    keras.layers.Conv2D(120, (5, 5), padding='same', activation='relu'),\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(84, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "#Compiling the model with a loss, optimizer, and other metrics\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "#Shows the whole network topology for the compiled CNN\n",
    "model.summary()\n",
    "\n",
    "#Training the network.\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_valid,y_valid))\n",
    "\n",
    "#Extracting the weights and biases from the neural network by layer name.\n",
    "hidden1_weights = model.get_layer(\"deep1\").weights\n",
    "hidden1_bias = model.get_layer(\"deep1\").bias.numpy()\n",
    "\n",
    "#Using the trained model to make predictions based on the input\n",
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "\n",
    "#Predicts what the image represents. \n",
    "x_test = x_test / 255.0 #Normalizes the input images\n",
    "predictions = probability_model.predict(x_test)\n",
    "\n",
    "# #Returns the most probable output layer based on the input image at index 3\n",
    "print('Predicted value: ' + str(np.argmax(predictions[3])) + ', actual digit: ' + str(y_test[3]))\n",
    "\n",
    "array = x_test[3]\n",
    "\n",
    "#Show the current image\n",
    "plt.figure()\n",
    "plt.imshow(x_test[3], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlTPm71d9c0A"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sk3iCH7b9c0A"
   },
   "source": [
    "# Problem 3\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[7, 5, 0, 0, 3, 2], [6, 4, 5, 1, 4, 8], [9, 0, 2, 2, 5, 4],  [6, 3, 4, 7, 9, 8], [5, 7, 5, 6, 9, 0], [7, 9, 0, 8, 2, 3]])\n",
    "f = np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
